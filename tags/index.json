[{"content":"ƒê·ªÉ ti·∫øp t·ª•c cho chu·ªói c√°c b√†i vi·∫øt v·ªÅ machine learning th√¨ h√¥m nay ch√∫ng ta s·∫Ω ti·∫øp t·ª•c t√¨m hi·ªÉu m·ªôt kh√°i ni·ªám r·∫•t quan tr·ªçng trong b√†i to√°n machine learning ƒë√≥ l√† l√†m s·∫°ch d·ªØ li·ªáu(data cleaning).\nƒê·ªÉ hi·ªÉu ƒë∆∞·ª£c t·ªïng quan v·ªÅ data cleaning th√¨ ƒë·∫ßu ti√™n ch√∫ng ta s·∫Ω t√¨m hi·ªÉu v·ªÅ kh√°i ni·ªám v√† nh·ªØng l·ª£i √≠ch c·ªßa vi·ªác l√†m s·∫°ch d·ªØ li·ªáu nh√©.\n1. Data cleaning Data cleaning thu·ªôc m·ªôt trong c√°c giai ƒëo·∫°n c·ªßa Data preparation ( b√†i ti·∫øp theo ch√∫ng ta s·∫Ω t√¨m hi·ªÉu v·ªÅ kh√°i ni·ªám n√†y) c√≤n g·ªçi l√† l√†m s·∫°ch d·ªØ li·ªáu, ƒë√¢y l√† b∆∞·ªõc ƒë·∫ßu ti√™n v√† c≈©ng l√† b∆∞·ªõc quan tr·ªçng nh·∫•t m√† m·ªói c√° nh√¢n ƒë·ªÅu ph·∫£i th·ª±c hi·ªán sau khi thu th·∫≠p ƒë∆∞·ª£c d·ªØ li·ªáu ƒë·ªÉ c√≥ m·ªôt k·∫øt qu·∫£ d·ª± ƒëo√°n ch√≠nh x√°c. M·ª•c ƒë√≠ch c·ªßa b∆∞·ªõc n√†y l√† lo·∫°i b·ªè c√°c d·ªØ li·ªáu \u0026ldquo;nhi·ªÖu\u0026rdquo;, d·ªØ li·ªáu kh√¥ng c·∫ßn thi·∫øt, kh√¥ng ƒë·∫ßy ƒë·ªß th√¥ng tin - ƒë√¢y ƒë∆∞·ª£c xem l√† nh·ªØng v·∫•n ƒë·ªÅ lu√¥n hi·ªán h·ªØu trong m·ªçi b·ªô d·ªØ li·ªáu.\nC√¥ng vi·ªác c·ª• th·ªÉ trong Data cleaning l√† x·ª≠ l√Ω c√°c \u0026ldquo;missing value\u0026rdquo;, c√°c nhi·ªÖu v√† d·ªØ li·ªáu kh√¥ng nh·∫•t qu√°n, kh√¥ng c·∫ßn thi·∫øt s·∫Ω ƒë∆∞·ª£c lo·∫°i b·ªè.\nK·∫øt qu·∫£ c·ªßa b∆∞·ªõc Data cleaning l√† m·ªôt b·ªô d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch, kh√¥ng c√≤n t√°c nh√¢n g√¢y ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c b∆∞·ªõc sau trong vi·ªác chu·∫©n b·ªã d·ªØ li·ªáu ( Data preparation).\n2. Th·ª±c hi·ªán 2.1. T·∫£i d·ªØ li·ªáu H√¥m nay m√¨nh s·∫Ω s·ª≠ d·ª•ng m·ªôt b·ªô d·ªØ li·ªáu th·∫≠t l√† d·ª± ƒëo√°n gi√° nh√† t·∫°i ti·ªÉu bang California Hoa K·ª≥ c√°c b·∫°n c√≥ th·ªÉ t·∫£i d·ªØ li·ªáu t·∫°i ƒë√¢y\nCh√∫ng ta v·∫´n s·ª≠ d·ª•ng pandas ƒë·ªÉ load d·ªØ li·ªáu:\n1 2 3 4 5 6 7 8  import os import tarfile from six.moves import urllib import pandas as pd url = \u0026#34;https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\u0026#34; names = [\u0026#39;longitude\u0026#39;, \u0026#39;latitude\u0026#39;, \u0026#39;housing_median_age\u0026#39;, \u0026#39;total_rooms\u0026#39;, \u0026#39;total_bedrooms\u0026#39;, \u0026#39;population\u0026#39;, \u0026#39;households\u0026#39;, \u0026#39;median_income\u0026#39;, \u0026#39;median_house_value\u0026#39;, \u0026#39;ocean_proximity\u0026#39;] housing = pd.read_csv(url)   ·ªû b√†i tr∆∞·ªõc m√¨nh ƒë√£ gi·ªõi thi·ªáu m·ªôt s·ªë ph∆∞∆°ng ph√°p ƒë·ªÉ hi·ªÉu ƒë∆∞·ª£c d·ªØ li·ªáu, n·∫øu c√°c b·∫°n ch∆∞a ƒë·ªçc th√¨ tham kh·∫£o t·∫°i ƒë√¢y\nNh∆∞ng ƒë·ªÉ ph·ª•c v·ª• cho c√°c b∆∞·ªõc ti·∫øp theo th√¨ ch√∫ng ta c·∫ßn ph·∫£i nh√¨n qua v·ªÅ d·ªØ li·ªáu m·ªôt ch√∫t.\n1  housing.head()       longitude latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value ocean_proximity     0 -122.23 37.88 41.0 880.0 129.0 322.0 126.0 8.3252 452600.0 NEAR BAY   1 -122.22 37.86 21.0 7099.0 1106.0 2401.0 1138.0 8.3014 358500.0 NEAR BAY   2 -122.24 37.85 52.0 1467.0 190.0 496.0 177.0 7.2574 352100.0 NEAR BAY   3 -122.25 37.85 52.0 1274.0 235.0 558.0 219.0 5.6431 341300.0 NEAR BAY   4 -122.25 37.85 52.0 1627.0 280.0 565.0 259.0 3.8462 342200.0 NEAR BAY    1  housing.shape    (20640, 10)\n D·ªØ li·ªáu ch√∫ng ta bao g·ªìm 10 c·ªôt (longitude, latitude, housing_median_age, total_rooms, total_bed rooms, population, households, median_income, median_house_value, and ocean_proximity) v√† 20640 h√†ng ( l∆∞u √Ω: m·ªói h√†ng ·ªü ƒë√¢y c√≥ nghƒ©a l√† m·ªói instances, v√† m·ªói c·ªôt l√† m·ªôt attribute) .\n1  housing.info()   H√†m info r·∫•t h·ª©u √≠ch trong vi·ªác m√¥ t·∫£ d·ªØ li·ªáu, n√≥ gi√∫p ch√∫ng ta bi·∫øt ƒë∆∞·ª£c l√† s·ªë h√†ng, ki·ªÉu d·ªØ li·ªáu c·ªßa m·ªói attribute v√† s·ªë l∆∞·ª£ng non-null values. B·∫°n c√≥ th·ªÉ th·∫•y k·∫øt qu·∫£ ·ªü ph√≠a tr√™n. Ch√∫ √Ω r·∫±ng \u0026ldquo;total_bedrooms\u0026rdquo; attribute ch·ªâ c√≥ 20433 non-null values, c√≥ nghƒ©a l√† c√≥ 207 h√†ng kh√¥ng c√≥ gi√° tr·ªã v√† ƒë√¢y g·ªçi l√† missing value.\nM·ªôt ch√∫ √Ω kh√°c l√† h·∫ßu h·∫øt c√°c gi√° tr·ªã c·ªßa c√°c attributes ƒë·ªÅu l√† d·∫°ng s·ªë, ch·ªâ c√≥ \u0026ldquo;ocean_proximity\u0026rdquo; l√† d·∫°ng object, n√≥ l√† m·ªôt ki·ªÉu c·ªßa python object nh∆∞ng khi ch√∫ng ta loaded d·ªØ li·ªáu ·ªü d·∫°ng CSV th√¨ n√≥ s·∫Ω ph·∫£i l√† ·ªü d·∫°ng text. D·ªØ li·ªáu m√† ch√∫ng ta ƒëang th·∫•y ch·ªâ l√† 5 h√†ng ƒë·∫ßu ti√™n, c√≥ th·ªÉ b·∫°n th·∫•y n√≥ ch·ªâ to√†n l√† NEAR BAY nh∆∞ng th·ª±c t·∫ø c√≥ nhi·ªÅu categorical kh√°c nhau:\n1  housing[\u0026#34;ocean_proximity\u0026#34;].value_counts()    \u0026lt;1H OCEAN: 9136\nINLAND: 6551\nNEAR OCEAN: 2658\nNEAR BAY : 2290\nISLAND : 5\nName: ocean_proximity, dtype: int64\n Nh∆∞ v·∫≠y ch√∫ng ta th·∫•y c√≥ 9136 h√†ng l√† OCEAN, 6551 l√† INLAND\u0026hellip; Ch√∫ng ta b·∫Øt ƒë·∫ßu v√†o ph·∫ßn ch√≠nh c·ªßa b√†i vi·∫øt.\nNh√¨n v√†o d·ªØ li·ªáu ch√∫ng ta bi·∫øt s·∫Ω c√≥ m·ªôt c·ªôt l√† label trong t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c g·ªçi l√† nh√£n, c·ª• th·ªÉ ·ªü ƒë√¢y l√† \u0026ldquo;median_house_value \u0026quot; hay c√≤n goi l√† gi√° nh√†. Ch√≠nh v√¨ v·∫≠y m√¨nh s·∫Ω t√°ch c·ªôt n√†y ri√™ng ra ƒë·ªÉ d·ªÖ d√†ng trong vi·ªác x·ª≠ l√Ω, c√≤n b√†i sau ch√∫ng ta s·∫Ω x·ª≠ l√Ω n√≥ trong b√†i vi·∫øt v·ªÅ chu·∫©n b·ªã d·ªØ li·ªáu.\n1 2  housing = housing.drop(\u0026#34;median_house_value\u0026#34;, axis=1) # drop labels for training set housing.head()       longitude latitude housing_median_age total_rooms total_bedrooms population households median_income ocean_proximity     0 -122.23 37.88 41.0 880.0 129.0 322.0 126.0 8.3252 NEAR BAY   1 -122.22 37.86 21.0 7099.0 1106.0 2401.0 1138.0 8.3014 NEAR BAY   2 -122.24 37.85 52.0 1467.0 190.0 496.0 177.0 7.2574 NEAR BAY   3 -122.25 37.85 52.0 1274.0 235.0 558.0 219.0 5.6431 NEAR BAY   4 -122.25 37.85 52.0 1627.0 280.0 565.0 259.0 3.8462 NEAR BAY    Ch√∫ng ta ƒë√£ lo·∫°i b·ªè c·ªôt gi√° nh√† ƒëi, b√¢y gi·ªù ch·ªâ c√≤n 9 c·ªôt.\nCh√∫ng ta l∆∞u √Ω m·ªôt ƒëi·ªÅu r·∫±ng h·∫ßu h·∫øt c√°c thu·∫≠t to√°n Machine Learning kh√¥ng th·ªÉ l√†m vi·ªác ƒë∆∞·ª£c v·ªõi nh·ªØng features m√† thi·∫øu d·ªØ li·ªáu ( missing features) ch√≠nh v√¨ v·∫≠y Data cleaning l√† b∆∞·ªõc r·∫•t quan tr·ªçng m√† ch√∫ng ta s·∫Ω kh√¥ng th·ªÉ b·ªè qua n·∫øu ch√∫ng ta kh√¥ng mu·ªën c√≥ m·ªôt k·∫øt qu·∫£ d·ª± ƒëo√°n t·ªìi.\nNh∆∞ m√¨nh ƒë√£ ƒë·ªÅ c·∫≠p tr∆∞·ªõc ƒë√≥ l√† \u0026ldquo;total_bedrooms\u0026rdquo; attribute c√≥ m·ªôt s·ªë d·ªØ li·ªáu b·ªã thi·∫øu. ƒê·ªÉ ƒë∆∞·ª£c r√µ h∆°n ch√∫ng ta s·∫Ω show k·∫øt qu·∫£ sau ƒë√¢y:\n1 2  sample_incomplete_rows = housing[housing.isnull().any(axis=1)] sample_incomplete_rows.head()       longitude latitude housing_median_age total_rooms total_bedrooms population households median_income ocean_proximity     290 -122.16 37.77 47.0 1256.0 NaN 570.0 218.0 4.3750 NEAR BAY   341 -122.17 37.75 38.0 992.0 NaN 732.0 259.0 1.6196 NEAR BAY   538 -122.28 37.78 29.0 5154.0 NaN 3741.0 1273.0 2.5762 NEAR BAY   563 -122.24 37.75 45.0 891.0 NaN 384.0 146.0 4.9489 NEAR BAY   696 -122.10 37.69 41.0 746.0 NaN 387.0 161.0 3.9063 NEAR BAY    Nh∆∞ ch√∫ng ta th·∫•y ·ªü tr√™n, c·ªôt n√†o c√≥ NaN c√≥ nghƒ©a l√† ƒëang kh√¥ng c√≥ gi√° tr·ªã n√†o, m·ªôt l√† ƒëang ƒë·ªÉ tr·ªëng hai l√† m·∫∑c ƒë·ªãnh l√† NaN v√† c√¥ng vi·ªác c·ªßa ch√∫ng ta l√† s·∫Ω ƒëi gi·∫£i quy·∫øt ch√∫ng.\nƒê·ªÉ x·ª≠ l√Ω c√°c missing value th√¨ ch√∫ng ta c√≥ 3 l·ª±a ch·ªçn:\n L·ª±a ch·ªçn 1: lo·∫°i b·ªè nh·ªØng h√†ng n√†o m√† gi√° tr·ªã ƒë√≥ l√† NaN L·ª±a ch·ªçn 2: lo·∫°i b·ªè to√†n b·ªô c·ªôt n√†o m√† c√≥ b·∫•t k·ª≥ m·ªôt gi√° tr·ªã NaN n√†o L·ª±a ch·ªçn 3: thay m·ªôt gi√° tr·ªã b·∫•t k·ª≥ v√†o gi√° tr·ªã NaN( v√≠ d·ª•: gi√° tr·ªã 0, gi√° tr·ªã mean, gi√° tr·ªã median\u0026hellip;).  1 2 3 4  housing.dropna(subset=[\u0026#34;total_bedrooms\u0026#34;]) # option 1  housing.drop(\u0026#34;total_bedrooms\u0026#34;, axis=1) # option 2  median = housing[\u0026#34;total_bedrooms\u0026#34;].median() # option 3  housing[\u0026#34;total_bedrooms\u0026#34;].fillna(median, inplace=True)   N·∫øu ch√∫ng ta ch·ªçn l·ª±a ch·ªçn 3 th√¨ c·∫ßn ph·∫£i t√≠nh gi√° tr·ªã median tr√™n t·∫≠p training set v√† l·∫•y gi√° tr·ªã ƒë√≥ ƒë·ªÉ thay v√†o c√°c gi√° tr·ªã NaN trong training set, nh∆∞ng b·∫°n ƒë·ª´ng qu√™n l∆∞u ch√∫ng l·∫°i ƒë·ªÉ s·ª≠ d·ª•ng cho t·∫≠p test khi b·∫°n mu·ªën ƒë√°nh gi√° model s·ª≠ d·ª•ng t·∫≠p test set. Ok, ch√∫ng ta b·∫Øt ƒë·∫ßu xem k·∫øt qu·∫£ c·ªßa t·ª´ng l·ª±a ch·ªçn nh√©:\nTrong l·ª±a ch·ªçn m·ªôt ch√∫ng ta s·ª≠ d·ª•ng h√†m dropna t·ª©c l√† x√≥a nh·ªØng h√†ng n√†o m√† c√≥ √≠t nh·∫•t m·ªôt gi√° tr·ªã NaN.\n1  sample_incomplete_rows.dropna(subset=[\u0026#34;total_bedrooms\u0026#34;]) # option 1       longitude latitude housing_median_age total_rooms total_bedrooms population households median_income ocean_proximity    Nh∆∞ v·∫≠y l√† ch√∫ng ta ƒë√£ x√≥a t·∫•t c·∫£ c√°c h√†ng c√≥ gi√° tr·ªã NaN. C√°c b·∫°n l∆∞u √Ω r·∫±ng l√† ƒë√¢y l√† ch√∫ng ta ƒëang x·ª≠ l√Ω tr√™n nh·ªØng h√†ng c√≥ gi√° tr·ªã NaN, ch·ª© nhi·ªÅu b·∫°n nh√¨n v√†o b·∫£ng tr√™n c√≥ th·ªÉ hi·ªÉu nh·∫ßm l√† to√†n b·ªô data ƒë√£ b·ªã x√≥a s·∫°ch nh∆∞ng kh√¥ng ph·∫£i, m√¨nh ƒëang x√©t nh·ªØng h√†ng c√≥ gi√° tr·ªã NaN v√† d·ªØ li·ªáu c·ªßa ch√∫ng ta ch·ªâ m·∫•t to√†n b·ªô h√†ng ch·ª©a gi√° tr·ªã NaN m√† th√¥i(c·ª• th·ªÉ ·ªü ƒë√¢y c√≥ 207 h√†ng) c√≤n c√°c h√†ng c√≤n l·∫°i v·∫´n gi·ªØ nguy√™n v√† t∆∞∆°ng t·ª± nh∆∞ c√°c l·ª±a ch·ªçn kh√°c.\n1  sample_incomplete_rows.drop(\u0026#34;total_bedrooms\u0026#34;, axis=1).head() # option 2   Ch√∫ng ta s·ª≠ d·ª•ng h√†m drop ƒë·ªÉ x√≥a c·ªôt b·∫•t k·ª≥ ch√∫ng ta mu·ªën, ·ªü ƒë√¢y ch√∫ng ta x√≥a c·ªôt c√≥ ch·ª©a NaN \u0026ldquo;total_bedrooms\u0026rdquo;.\n    longitude latitude housing_median_age total_rooms population households median_income ocean_proximity      290 -122.16 37.77 47.0 1256.0 570.0 218.0 4.3750 NEAR BAY    341 -122.17 37.75 38.0 992.0 732.0 259.0 1.6196 NEAR BAY    538 -122.28 37.78 29.0 5154.0 3741.0 1273.0 2.5762 NEAR BAY    563 -122.24 37.75 45.0 891.0 384.0 146.0 4.9489 NEAR BAY    696 -122.10 37.69 41.0 746.0 387.0 161.0 3.9063 NEAR BAY     Ok, nh∆∞ v·∫≠y c·ªôt \u0026ldquo;total_bedrooms\u0026rdquo; c·ªßa ch√∫ng ta ƒë√£ b·ªã x√≥a.\nL·ª±a ch·ªçn 3 th√¨ nh∆∞ m√¨nh ƒë√£ n√≥i ·ªü tr√™n v√† b√¢y gi·ªù ch√∫ng ta s·∫Ω xem k·∫øt qu·∫£ n√≥ nh∆∞ th·∫ø n√†o nh√©.\n1 2 3  median = housing[\u0026#34;total_bedrooms\u0026#34;].median() sample_incomplete_rows[\u0026#34;total_bedrooms\u0026#34;].fillna(median, inplace=True) # option 3 sample_incomplete_rows.head()   H√†m fillna l√† h√†m m√† l·∫•y gi√° tr·ªã b·∫•t k·ª≥ m√† ch√∫ng ta mu·ªën ƒë·ªÉ thay th·∫ø cho to√†n b·ªô gi√° tr·ªã NaN c·ªßa c·ªôt ƒë√≥, ·ªü ƒë√¢y l√† median ( ch√∫ng c√≥ th·ªÉ l√† gi√° tr·ªã 0, ho·∫∑c mean)\n    longitude latitude housing_median_age total_rooms total_bedrooms population households median_income ocean_proximity     290 -122.16 37.77 47.0 1256.0 435.0 570.0 218.0 4.3750 NEAR BAY   341 -122.17 37.75 38.0 992.0 435.0 732.0 259.0 1.6196 NEAR BAY   538 -122.28 37.78 29.0 5154.0 435.0 3741.0 1273.0 2.5762 NEAR BAY   563 -122.24 37.75 45.0 891.0 435.0 384.0 146.0 4.9489 NEAR BAY   696 -122.10 37.69 41.0 746.0 435.0 387.0 161.0 3.9063 NEAR BAY    Ch√∫ng ta th·∫•y gi√° tr·ªã median l√† 435.0 v√† ƒë√£ ƒë∆∞·ª£c thay th·∫ø cho gi√° tr·ªã NaN r·ªìi nh√©.\nVi·ªác l·ª±a ch·ªçn 3 ph∆∞∆°ng √°n tr√™n l√† t√πy v√†o b√†i to√°n, v√† l∆∞·ª£ng gi√° tr·ªã NaN. Nh∆∞ng h·∫ßu h·∫øt ng∆∞·ªùi ta khuy·∫øn kh√≠ch s·ª≠ d·ª•ng l·ª±a ch·ªçn 3 n·∫øu trong tr∆∞·ªùng h·ª£p l∆∞·ª£ng gi√° tr·ªã NaN qu√° nh·ªè so v·ªõi to√†n b·ªô d·ªØ li·ªáu.\nOK, v·∫≠y ch√∫ng ta ƒë√£ xong vi·ªác x·ª≠ l√Ω \u0026ldquo;missing value\u0026rdquo;, th·∫ø l√† t·∫°m ·ªïn üòÑ. M·ªõi ch·ªâ t·∫°m ·ªïn th√¥i nh√© ch·ª© ch∆∞a ·ªïn ƒë√¢u, c√≤n ti·∫øp t·ª•c.\nNh∆∞ ch√∫ng ta th·∫•y h·∫ßu h·∫øt to√†n b·ªô c√°c attributes ƒë·ªÅu l√† gi√° tr·ªã s·ªë, nh∆∞ng l·∫°i c√≥ m·ªôt attribute l√† text, t·ªõi ƒë√¢y c√≥ nhi·ªÅu b·∫°n th·∫Øc m·∫Øc r·∫±ng n·∫øu l√† text th√¨ sao t√≠nh ƒë∆∞·ª£c median, th·∫≠t may l√† ·ªü tr√™n m√¨nh ch·ªâ s·ª≠ d·ª•ng c·ªôt total_bedrooms. M√¨nh tr·∫£ l·ªùi cho c√°c b·∫°n l√† text th√¨ kh√¥ng th·ªÉ t√≠nh ƒë∆∞·ª£c gi√° tr·ªã median nh√©, c√≤n n·∫øu c√°c b·∫°n mu·ªën t√≠nh gi√° tr·ªã median tr√™n to√†n b·ªô attributes th√¨ c√°c b·∫°n s·∫Ω ph·∫£i lo·∫°i b·ªè attribute n√†o m√† gi√° tr·ªã c·ªßa n√≥ thu·ªôc d·∫°ng text. Nh∆∞ng b√¢y gi·ªù ch√∫ng ta s·∫Ω x·ª≠ l√Ω n√≥.\n1 2  housing_text = housing[[\u0026#39;ocean_proximity\u0026#39;]] housing_text.head()       ocean_proximity     0 NEAR BAY   1 NEAR BAY   2 NEAR BAY   3 NEAR BAY   4 NEAR BAY    H·∫ßu h·∫øt c√°c thu·∫≠t to√°n machine learning l√†m vi·ªác v·ªõi s·ªë h∆°n l√† text ch√≠nh v√¨ v·∫≠y vi·ªác c·ªßa ch√∫ng ta b√¢y gi·ªù l√† chuy·ªÉn text th√†nh s·ªë th√¥i.\nTrong th∆∞ vi·ªán Scikit-Learn c√≥ hai h√†m ƒë·ªÉ l√†m vi·ªác n√†y cho ch√∫ng ta ƒë√≥ l√† LabelEncoder v√† OrdinalEncoder, b·∫£n ch·∫•t c·ªßa hai h√†m n√†y l√† chuy·ªÉn d·∫°ng text sang d·∫°ng s·ªë, ·ªü ƒë√¢y m√¨nh d√πng OrdinalEncoder.\n1 2 3 4  from sklearn.preprocessing import OrdinalEncoder ordinal_encoder = OrdinalEncoder() housing_text_encoded = ordinal_encoder.fit_transform(housing_text) housing_text_encoded[:10]    array([[0.],\n[0.],\n[4.],\n[1.],\n[0.],\n[1.],\n[0.],\n[1.],\n[0.],\n[0.]])\n OK, b√¢y gi·ªù ch√∫ng ta xem d·ªØ li·ªáu c·ªßa ch√∫ng ta tr√¥ng nh∆∞ th·∫ø n√†o sau khi l√†m s·∫°ch nh√©:\n1 2  housing[\u0026#34;ocean_proximity\u0026#34;] = housing_text_encoded housing.head()       longitude latitude housing_median_age total_rooms total_bedrooms population households median_income ocean_proximity     0 -122.23 37.88 41.0 880.0 129.0 322.0 126.0 8.3252 3.0   1 -122.22 37.86 21.0 7099.0 1106.0 2401.0 1138.0 8.3014 3.0   2 -122.24 37.85 52.0 1467.0 190.0 496.0 177.0 7.2574 3.0   3 -122.25 37.85 52.0 1274.0 235.0 558.0 219.0 5.6431 3.0   4 -122.25 37.85 52.0 1627.0 280.0 565.0 259.0 3.8462 3.0    1  housing[\u0026#34;ocean_proximity\u0026#34;].dtypes    dtype(\u0026lsquo;float64\u0026rsquo;)\n K·∫øt qu·∫£ ch√∫ng ta th·∫•y \u0026ldquo;ocean_proximity\u0026rdquo; attribute ƒë√£ chuy·ªÉn t·ª´ text ban ƒë·∫ßu th√†nh ki·ªÉu d·ªØ li·ªáu s·ªë (float).\nNh∆∞ v·∫≠y ch√∫ng ta ƒë√£ ho√†n th√†nh ƒë∆∞·ª£c m·ª•c ti√™u c·ªßa ch√∫ng ta trong b√†i vi·∫øt n√†y. K·∫øt qu·∫£ l√† m·ªôt b·ªô d·ªØ li·ªáu m√† ch√∫ng ta mong mu·ªën.\n3. T·ªïng k·∫øt K·∫øt qu·∫£ nghi√™n c·ª©u cho th·∫•y ƒë·ªÉ l√†m m·ªôt b√†i to√°n Machine Learning th√†nh c√¥ng th√¨ vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu chi·∫øm kho·∫£ng 70% th·ªùi gian c·ªßa ch√∫ng ta, ƒë·ªÉ c√≥ m·ªôt k·∫øt qu·∫£ v·ªõi ƒë·ªô ch√≠nh x√°c nh∆∞ mong mu·ªën th√¨ vi·ªác l√†m s·∫°ch d·ªØ li·ªáu l√† b∆∞·ªõc c·ª±c k·ª≥ quan tr·ªçng v√† kh√¥ng th·ªÉ b·ªè qua khi ch√∫ng ta l√†m m·ªôt ·ª©ng d·ª•ng machine learning.\nL√†m s·∫°ch d·ªØ li·ªáu l√† vi·ªác ƒë√≤i h·ªèi ch√∫ng ta ph·∫£i c√≥ kinh nghi·ªám k·∫øt h·ª£p v·ªõi nhi·ªÅu ki·∫øn th·ª©c. Qua b√†i vi·∫øt n√†y m√¨nh ƒë√£ h∆∞·ªõng d·∫´n t·ªõi c√°c b·∫°n c√°ch th·ª±c hi·ªán ƒë·ªÉ ch√∫ng ta c√≥ m·ªôt b·ªô d·ªØ li·ªáu s·∫°ch l√† nh∆∞ th·∫ø n√†o. Hy v·ªçng r·∫±ng c√°c b·∫°n s·∫Ω √°p d·ª•ng hi·ªáu qu·∫£ trong qu√° tr√¨nh x√¢y d·ª±ng v√† hu·∫•n luy·ªán c√°c thu·∫≠t to√°n machine learning.\nB√†i vi·∫øt ti·∫øp theo m√¨nh s·∫Ω h∆∞·ªõng d·∫´n c√°ch ƒë·ªÉ chu·∫©n b·ªã m·ªôt b·ªô d·ªØ li·ªáu ho√†n ch·ªânh ƒë·ªÉ √°p d·ª•ng v√†o c√°c thu·∫≠t to√°n machine learning m·ªôt c√°ch hi·ªáu qu·∫£ nh·∫•t. C√°c b·∫°n ƒë√≥n ƒë·ªçc trong b√†i vi·∫øt ti·∫øp theo nh√©\n4. T√†i li·ªáu tham kh·∫£o   https://towardsdatascience.com/data-cleaning-with-python-and-pandas-detecting-missing-values-3e9c6ebcf78b\n  https://www.tutorialspoint.com/python_data_science/python_data_cleansing.htm\n  ","description":"K·ªπ thu·∫≠t x·ª≠ l√Ω d·ªØ li·ªáu cho b√†i to√°n Machine Learning","id":0,"section":"posts","tags":["data cleaning"],"title":"Data Cleaning trong Machine Learning ","uri":"https://tranvanly107.github.io/posts/data-clearning/"},{"content":"1. Ki·∫øn th·ª©c c·∫ßn c√≥ Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu v·ªõi b√†i vi·∫øt n√†y, vui l√≤ng ch·∫Øc ch·∫Øn r·∫±ng b·∫°n c√≥ ki·∫øn th·ª©c v·ªÅ Python. C√°c th∆∞ vi·ªán c·∫ßn thi·∫øt nh∆∞:\n Pandas Numpy Sklearn\nC√°c b·∫°n c√≥ th·ªÉ d√πng google colab ho·∫∑c jupyter ƒë·ªÉ code nh√©.  2. C√°c b∆∞·ªõc ƒë·ªÉ l√†m m·ªôt b√†i to√°n ML H·∫ßu h·∫øt to√†n b·ªô b√†i to√°n v·ªÅ Machine Learning ƒë·ªÅu tr·∫£i qua c√°c b∆∞·ªõc c∆° b·∫£n sau: ( M√¨nh s·∫Ω kh√¥ng n√≥i s√¢u v·ªÅ t·ª´ng b∆∞·ªõc, c√°c b·∫°n c·∫ßn t√¨m hi·ªÉu th√™m nh√©)\n X√°c ƒë·ªãnh v·∫•n ƒë·ªÅ. Chu·∫©n b·ªã d·ªØ li·ªáu ƒê√°nh gi√° thu·∫≠t to√°n C·∫£i thi·ªán k·∫øt qu·∫£ Hi·ªÉn th·ªã k·∫øt qu·∫£ d·ª± ƒëo√°n  3. B√†i to√°n Machine Learning C√°c b∆∞·ªõc ch√≠nh ƒë·ªÉ ch√∫ng ta x√¢y d·ª±ng b√†i to√°n nh∆∞ sau:\n C√†i ƒë·∫∑t Python v√† SciPy platform. T·∫£i d·ªØ li·ªáu v·ªÅ Hi·ªÉu d·ªØ li·ªáu Tr·ª±c quan h√≥a d·ªØ li·ªáu ƒê√°nh gi√° m·ªôt s·ªë thu·∫≠t to√°n D·ª± ƒëo√°n k·∫øt qu·∫£\nB√¢y gi·ªù ch√∫ng ta b·∫Øt ƒë·∫ßu nh√©.  3.1. C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt C√°c b·∫°n t·ª± c√†i ƒë·∫∑t Python ( 3.x) v√† c√°c th∆∞ vi·ªán sau:\n scipy numpy matplotlib pandas sklearn\nVi·ªác c√†i ƒë·∫∑t c√°c th·ª± vi·ªán n√†y r·∫•t ƒë∆°n gi·∫£n n√™n c√°c b·∫°n t·ª± t√¨m hi·ªÉu.\nC√†i ƒë·∫∑t scipy t·∫°i ƒë√¢y\nSau khi c√°c b·∫°n c√†i xong th√¨ c√°c b·∫°n test xem ƒë√£ th√†nh c√¥ng hay ch∆∞a:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  import sys\r# Python version\r print(\u0026#39;Python: {}\u0026#39;.format(sys.version))\r# scipy\r import scipy\rprint(\u0026#39;scipy: {}\u0026#39;.format(scipy.__version__))\r# numpy\r import numpy\rprint(\u0026#39;numpy: {}\u0026#39;.format(numpy.__version__))\r# matplotlib\r import matplotlib\rprint(\u0026#39;matplotlib: {}\u0026#39;.format(matplotlib.__version__))\r# pandas\r import pandas\rprint(\u0026#39;pandas: {}\u0026#39;.format(pandas.__version__))\r# scikit-learn\r import sklearn\rprint(\u0026#39;sklearn: {}\u0026#39;.format(sklearn.__version__))\r  N·∫øu c√°c b·∫°n ƒë√£ c√†i th√†nh c√¥ng th√¨ k·∫øt qu·∫£ c√≥ d·∫°ng th·∫ø n√†y:\n Python: 3.7.4 (default, Oct 19 2019, 05:21:45) [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]\nscipy: 1.4.1\nnumpy: 1.17.3\nmatplotlib: 3.2.0\npandas: 0.25.1\nsklearn: 0.22.2\n C√≤n n·∫øu c√°c b·∫°n c√†i ƒë·∫∑t b·ªã l·ªói th√¨ c√≥ th·ªÉ fix l·ªói t·∫°i ƒë√¢y.\n3.2. T·∫£i d·ªØ li·ªáu Trong b√†i vi·∫øt n√†y ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng d·ªØ li·ªáu c√≥ s·∫µn tr√™n google.\nC√°c b·∫°n c√≥ th·ªÉ t√¨m hi·ªÉu d·ªØ li·ªáu t·∫°i ƒë√¢y.\n3.2.1. import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt Ti·∫øp theo ch√∫ng ta s·∫Ω import c√°c th∆∞ vi·ªán d∆∞·ªõi ƒë√¢y ƒë·ªÉ s·ª± d·ª•ng trong b√†i to√°n.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # Load libraries\r from pandas import read_csv\rfrom pandas.plotting import scatter_matrix\rfrom matplotlib import pyplot\rfrom sklearn.model_selection import train_test_split\rfrom sklearn.model_selection import cross_val_score\rfrom sklearn.model_selection import StratifiedKFold\rfrom sklearn.metrics import classification_report\rfrom sklearn.metrics import confusion_matrix\rfrom sklearn.metrics import accuracy_score\rfrom sklearn.linear_model import LogisticRegression\rfrom sklearn.tree import DecisionTreeClassifier\rfrom sklearn.neighbors import KNeighborsClassifier\rfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\rfrom sklearn.naive_bayes import GaussianNB\rfrom sklearn.svm import SVC\r  3.2.2. T·∫£i d·ªØ li·ªáu v·ªÅ Ch√∫ng ta s·∫Ω s·ª≠ d·ª•ng pandas ƒë·ªÉ t·∫£i d·ªØ li·ªáu v·ªÅ. V√† c≈©ng s·∫Ω s·ª≠ d·ª•ng pandas ƒë·ªÉ khai ph√° v√† tr·ª±c quan h√≥a d·ªØ li·ªáu.\n1 2 3 4  # Load dataset\r url = \u0026#34;https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\u0026#34;\rnames = [\u0026#39;sepal-length\u0026#39;, \u0026#39;sepal-width\u0026#39;, \u0026#39;petal-length\u0026#39;, \u0026#39;petal-width\u0026#39;, \u0026#39;class\u0026#39;]\rdataset = read_csv(url, names=names)\r  Ch√∫ng ta s·ª≠ d·ª•ng h√†m read_csv v√† ƒë∆∞·ª£c tr·∫£ v·ªÅ m·ªôt dataframe, ch√∫ng ta s·∫Ω xem k·∫øt qu·∫£ sau.\nN·∫øu c√°c b·∫°n g·∫∑p l·ªói khi load th√¨ b·∫°n c√≥ th·ªÉ download iris.csv.\n3.3. Khai ph√° d·ªØ li·ªáu B√¢y gi·ªù ch√∫ng ta xem d·ªØ li·ªáu n√≥ c√≥ g√¨ nh√©.\nCh√∫ng ta s·∫Ω th·ª±c hi·ªán m·ªôt s·ªë c√°ch ti·∫øp c·∫≠n d∆∞·ªõi ƒë√¢y:\n Chi·ªÅu c·ªßa d·ªØ li·ªáu T·ªïng quan v·ªÅ d·ªØ li·ªáu Th·ªëng k√™ t·∫•t c·∫£ c√°c thu·ªôc t√≠nh c·ªßa d·ªØ li·ªáu Ph√¢n b·ªë c·ªßa d·ªØ li·ªáu\nB√¢y gi·ªù ch√∫ng ti·∫øn h√†nh ƒëi th·ª±c hi·ªán t·ª´ng m·ª•c m·ªôt nh√©:  3.3.1. Chi·ªÅu c·ªßa d·ªØ li·ªáu Chi·ªÅu c·ªßa d·ªØ li·ªáu cho ch√∫ng ta bi·∫øt l√† c√≥ bao nhi√™u h√†ng v√† bao nhi√™u c·ªôt c·ªßa to√†n b·ªô d·ªØ li·ªáu. ƒê·ªÉ xem chi·ªÅu d·ªØ li·ªáu ch√∫ng ta s·ª≠ d·ª•ng h√†m shape trong pandas.\nprint(dataset.shape)\rOutput: (150,5)\nC√≥ nghƒ©a l√† d·ªØ li·ªáu c·ªßa ch√∫ng ta c√≥ 150 h√†ng v√† 5 c·ªôt. N√≥i c√°ch kh√°c l√† c√≥ 150 ƒëi·ªÉm d·ªØ li·ªáu v√† 4 features, 1 class ch√≠nh l√† nh√£n m√† model c·∫ßn d·ª± ƒëo√°n.\n3.3.2. T·ªïng quan d·ªØ li·ªáu B√¢y gi·ªù ch√∫ng ta s·∫Ω xem r√µ h∆°n v·ªÅ d·ªØ li·ªáu nh√©. ƒê·ªÉ xem ch√∫ng ta ch·ªâ c·∫ßn d√πng h√†m head trong pandas nh∆∞ sau:\nprint(dataset.head(20))\rH√†m head gi√∫p ch√∫ng ta hi·ªÉn th·ªã n b·∫£n ghi ƒë·∫ßu ti√™n, ·ªü ƒë√¢y ch√∫ng s·∫Ω hi·ªÉn th·ªã 20 h√†ng ƒë·∫ßu ti√™n c·ªßa to√†n b·ªô d·ªØ li·ªáu.\n    sepal-length sepal-width petal-length petal-width class     0 5.1 3.5 1.4 0.2 Iris-setosa   1 4.9 3.0 1.4 0.2 Iris-setosa   2 4.7 3.2 1.3 0.2 Iris-setosa   3 4.6 3.1 1.5 0.2 Iris-setosa   4 5.0 3.6 1.4 0.2 Iris-setosa   5 5.4 3.9 1.7 0.4 Iris-setosa   6 4.6 3.4 1.4 0.3 Iris-setosa   7 5.0 3.4 1.5 0.2 Iris-setosa   8 4.4 2.9 1.4 0.2 Iris-setosa   9 4.9 3.1 1.5 0.1 Iris-setosa   10 5.4 3.7 1.5 0.2 Iris-setosa   11 4.8 3.4 1.6 0.2 Iris-setosa   12 4.8 3.0 1.4 0.1 Iris-setosa   13 4.3 3.0 1.1 0.1 Iris-setosa   14 5.8 4.0 1.2 0.2 Iris-setosa   15 5.7 4.4 1.5 0.4 Iris-setosa   16 5.4 3.9 1.3 0.4 Iris-setosa   17 5.1 3.5 1.4 0.3 Iris-setosa   18 5.7 3.8 1.7 0.3 Iris-setosa   19 5.1 3.8 1.5 0.3 Iris-setosa    ƒê√¢y l√† h√¨nh d·∫°ng c·ªßa m·ªôt dataframe. C√°c features c·ªßa d·ªØ li·ªáu bao g·ªìm: chi·ªÅu d√†i ƒë√†i hoa (sepal-length), chi·ªÅu r·ªông ƒë√†i hoa(sepal-width ), chi·ªÅu d√†i c√°nh hoa (petal-length), chi·ªÅu r·ªông c√°nh hoa(petal-width ).V√† c√≥ 3 classes m√† ch√∫ng ta c·∫ßn d·ª± ƒëo√°n ƒë√≥ l√†: Iris-setosa, Iris-versicolor, Iris-virginica. T·∫•t nhi√™n m·ªói lo√†i hoa s·∫Ω c√≥ c√°c features kh√°c nhau ƒë·ªÉ m√¥ h√¨nh n√≥ ph√¢n bi·ªát v√† ƒë∆∞a ra d·ª± ƒëo√°n ch√≠nh x√°c.\n3.3.3. Th·ªëng k√™ c√°c thu·ªôc t√≠nh c·ªßa d·ªØ li·ªáu B√¢y gi·ªù ch√∫ng ta s·∫Ω xem chi ti·∫øt h∆°n v·ªÅ c√°c features: Bao g·ªìm count(s·ªë l∆∞·ª£ng), mean(chi·ªÅu d√†i, chi·ªÅu r·ªông trung b√¨nh), min v√† max. C·ª• th·ªÉ nh∆∞ sau:\nprint(dataset.describe())\rV√† k·∫øt qu·∫£ l√†:\n    sepal-length sepal-width petal-length petal-width     count 150.000000 150.000000 150.000000 150.000000   mean 5.843333 3.054000 3.758667 1.198667   std 0.828066 0.433594 1.764420 0.763161   min 4.300000 2.000000 1.000000 0.100000   25% 5.100000 2.800000 1.600000 0.300000   50% 5.800000 3.000000 4.350000 1.300000   75% 6.400000 3.300000 5.100000 1.800000   max 7.900000 4.400000 6.900000 2.500000    Nh∆∞ chung ta th·∫•y ·ªü tr√™n ƒë·ªô d√†i v√† r·ªông c·ªßa t·ª´ng feature thu·ªôc c√πng ƒë∆°n v·ªã (cm) v√† c√πng n·∫±m trong kho·∫£ng t·ª´ 0-8 cm.\n3.3.4. Ph√¢n b·ªë d·ªØ li·ªáu B√¢y gi·ªù ch√∫ng ta xem s·ªë l∆∞·ª£ng c·ªßa t·ª´ng lo√†i hoa ( t·ª´ng class) b·∫±ng c√°ch:\nprint(dataset.groupby('class').size()\rV√† k·∫øt qu·∫£ s·∫Ω l√†:\n class\nIris-setosa 50\nIris-versicolor 50\nIris-virginica 50\n Ch√∫ng ta th·∫•y s·ªë l∆∞·ª£ng hoa ( class) ƒë·ªìng ƒë·ªÅu nhau v√† c√πng l√† 50.\nCode ƒë·∫ßy ƒë·ªß cho c√°c b∆∞·ªõc tr√™n nh∆∞ sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  # summarize the data\r from pandas import read_csv\r# Load dataset\r url = \u0026#34;https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\u0026#34;\rnames = [\u0026#39;sepal-length\u0026#39;, \u0026#39;sepal-width\u0026#39;, \u0026#39;petal-length\u0026#39;, \u0026#39;petal-width\u0026#39;, \u0026#39;class\u0026#39;]\rdataset = read_csv(url, names=names)\r# shape\r print(dataset.shape)\r# head\r print(dataset.head(20))\r# descriptions\r print(dataset.describe())\r# class distribution\r print(dataset.groupby(\u0026#39;class\u0026#39;).size())\r  3.4. Tr·ª±c quan d·ªØ li·ªáu Ch√∫ng ta ƒë√£ bi·∫øt ƒë∆∞·ª£c c∆° b·∫£n v·ªÅ d·ªØ li·ªáu, b√¢y gi·ªù l√† l√∫c ch√∫ng ta tr·ª±c quan h√≥a b·∫±ng bi·ªÉu ƒë·ªì.\nB∆∞·ªõc n√†y gi√∫p ch√∫ng ta hi·ªÉu r√µ h∆°n ph√¢n b·ªë chi ti·∫øt t·ª´ng lo√†i hoa(class) b·∫±ng c√°ch nh√¨n v√†o c√°c bi·ªÉu ƒë·ªì sau:\n3.4.1. Univariate Plots Bi·ªÉu ƒë·ªì n√†y gi√∫p ch√∫ng ta hi·ªÉu ƒë∆∞·ª£c ph√¢n b·ªë c·ªßa t·ª´ng feature.\ndataset.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\rpyplot.show()\rK·∫øt qu·∫£ hi·ªÉn th·ªã nh∆∞ sau:\nCh√∫ng ta c≈©ng c√≥ th·ªÉ t·∫°o ra c√°c bi·ªÉu ƒë·ªì histogram v·ªõi d·ªØ li·ªáu ƒë·∫ßu v√†o:\n# histograms\rdataset.hist()\rpyplot.show()\rK·∫øt qu·∫£ hi·ªÉn th·ªã nh∆∞ sau:\n3.4.2. Multivariate Plots B√¢y gi·ªù ch√∫ng ta c√≥ th·ªÉ th·∫•y s·ª± li√™n quan gi·ªØa c√°c features. Ch√∫ng ta s·ª≠ d·ª•ng scatter_matrix trong pandas ƒë·ªÉ th·∫•y ƒë∆∞·ª£c quan h·ªá c·ªßa c√°c features tr√™n to√†n b·ªô d·ªØ li·ªáu:\n# scatter plot matrix\rscatter_matrix(dataset)\rpyplot.show()\rCh√∫ng ta th·∫•y ƒë∆∞·ª£c s·ª± t∆∞∆°ng quan gi·ªØa ch√∫ng th√¥ng qua bi·ªÉu ƒë·ªì sau:\nCode ƒë·∫ßy ƒë·ªß cho c√°c b∆∞·ªõc tr√™n nh∆∞ sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # visualize the data\r from pandas import read_csv\rfrom pandas.plotting import scatter_matrix\rfrom matplotlib import pyplot\r# Load dataset\r url = \u0026#34;https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\u0026#34;\rnames = [\u0026#39;sepal-length\u0026#39;, \u0026#39;sepal-width\u0026#39;, \u0026#39;petal-length\u0026#39;, \u0026#39;petal-width\u0026#39;, \u0026#39;class\u0026#39;]\rdataset = read_csv(url, names=names)\r# box and whisker plots\r dataset.plot(kind=\u0026#39;box\u0026#39;, subplots=True, layout=(2,2), sharex=False, sharey=False)\rpyplot.show()\r# histograms\r dataset.hist()\rpyplot.show()\r# scatter plot matrix\r scatter_matrix(dataset)\rpyplot.show()\r  3.5. ƒê√°nh gi√° thu·∫≠t to√°n B√¢y gi·ªù l√† l√∫c ch√∫ng ta s·∫Ω th·ª≠ ch·ªçn m·ªôt v√†i model ƒë·ªÉ xem ƒë·ªô ch√≠nh x√°c c·ªßa t·ª´ng model tr√™n t·∫≠p test c·ªßa ch√∫ng ta nh√©.\nC√°c b∆∞·ªõc th·ª±c hi·ªán nh∆∞ sau:\n T√°ch m·ªôt ph·∫ßn d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° model ( validation dataset) Thi·∫øt l·∫≠p test harness ƒë·ªÉ s·ª≠ d·ª•ng 10-fold cross validation Ch·∫°y v√† d·ª± ƒëo√°n k·∫øt qu·∫£ tr√™n t·ª´ng model Ch·ªçn ra model c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t ƒë·ªÉ s·ª≠ d·ª•ng cu·ªëi c√πng\nok, b√¢y gi·ªù s·∫Ω v√†o chi ti·∫øt nh√©:  3.5.1. T√°ch m·ªôt ph·∫ßn d·ªØ li·ªáu (validation Dataset) Ch√∫ng ta s·∫Ω chia d·ªØ li·ªáu c·ªßa ch√∫ng ta ra th√†nh 2 ph·∫ßn: 80% d·ªØ li·ªáu d√πng ƒë·ªÉ hu·∫•n luy·ªán model ( training data), 20% c√≤n l·∫°i l√† d√πng ƒë·ªÉ ƒë√°nh gi√° model(validation data)\n1 2 3 4 5  # Split-out validation dataset\r array = dataset.values\rX = array[:,0:4]\ry = array[:,4]\rX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1)\r  Ch√∫ng ta l·∫•y b·ªën c·ªôt ƒë·∫ßu ti√™n (X) l√† c√°c features hay c√≤n g·ªçi l√† ƒë·∫∑c t√≠nh c·ªßa d·ªØ li·ªáu(attributes), c·ªôt cu·ªëi c√πng l√† (y) nh√£n c·ªßa d·ªØ li·ªáu.\nB√¢y gi·ªù ch√∫ng ta ƒë√£ chu·∫©n b·ªã ƒë∆∞·ª£c d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß cho vi·ªác training v√† testing r·ªìi.\n3.5.2. Cross validation Ch√∫ng ta s·∫Ω t·∫°o ra 10 fold cross validation ƒë·ªÉ estimate model.\nC·ª• th·ªÉ l√† ch√∫ng ta chia d·ªØ li·ªáu train ra l√†m 10 ph·∫ßn b·∫±ng nhau, l·∫•y 9 ph·∫ßn cho vi·ªác train v√† ph·∫ßn c√≤n l·∫°i l√† ƒë·ªÉ test trong l√∫c train. ƒê·ªÉ hi·ªÉu r√µ h∆°n v·ªÅ cross validation th√¨ c√°c b·∫°n c√≥ th·ªÉ t√¨m hi·ªÉu t·∫°i ƒë√¢y nh√©.\n3.5.3. Build models Ch√∫ng ta b√¢y gi·ªù s·∫Ω kh√¥ng th·ªÉ bi·∫øt ƒë∆∞·ª£c model n√†o s·∫Ω t·ªët nh·∫•t.\nSau ƒë√¢y l√† nh·ªØng model m√¨nh d√πng ƒë·ªÉ ch·∫°y v√† d·ª± ƒëo√°n ƒë·ªô ch√≠nh x√°c.\n Logistic Regression (LR) Linear Discriminant Analysis (LDA) K-Nearest Neighbors (KNN). Classification and Regression Trees (CART). Gaussian Naive Bayes (NB). Support Vector Machines (SVM).\nC·ª• th·ªÉ t·ª´ng model th√¨ m√¨nh s·∫Ω c·∫≠p nh·∫≠t sau n·∫øu c√≥ th·ªùi gian nh√©.\nN√†o b√¢y gi·ªù ch√∫ng ta s·∫Ω code v√† ch·∫°y nh√©:  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # Spot Check Algorithms\r models = []\rmodels.append((\u0026#39;LR\u0026#39;, LogisticRegression(solver=\u0026#39;liblinear\u0026#39;, multi_class=\u0026#39;ovr\u0026#39;)))\rmodels.append((\u0026#39;LDA\u0026#39;, LinearDiscriminantAnalysis()))\rmodels.append((\u0026#39;KNN\u0026#39;, KNeighborsClassifier()))\rmodels.append((\u0026#39;CART\u0026#39;, DecisionTreeClassifier()))\rmodels.append((\u0026#39;NB\u0026#39;, GaussianNB()))\rmodels.append((\u0026#39;SVM\u0026#39;, SVC(gamma=\u0026#39;auto\u0026#39;)))\r# evaluate each model in turn\r results = []\rnames = []\rfor name, model in models:\rkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\rcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=\u0026#39;accuracy\u0026#39;)\rresults.append(cv_results)\rnames.append(name)\rprint(\u0026#39;%s: %f(%f)\u0026#39; % (name, cv_results.mean(), cv_results.std()))\r  3.5.4. Ch·ªçn model c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t B√¢y gi·ªù ch√∫ng ta ƒë√£ ch·∫°y ƒë∆∞·ª£c 6 model v√† m·ªói model s·∫Ω cho ra ƒë·ªô ch√≠nh x√°c kh√°c nhau. Gi·ªù l√† l√∫c ch√∫ng ta so s√°nh t·ª´ng k·∫øt qu·∫£ v√† ch·ªçn ra model c√≥ ƒë·ªô ch√≠nh x√°c t·ªët nh·∫•t.\nCh·∫°y xong ƒëo·∫°n code tr√™n th√¨ ch√∫ng ta nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ sau:\n LR: 0.960897 (0.052113)\nLDA: 0.973974 (0.040110)\nKNN: 0.957191 (0.043263)\nCART: 0.957191 (0.043263)\nNB: 0.948858 (0.056322)\nSVM: 0.983974 (0.032083)\n Nh∆∞ ch√∫ng ta th·∫•y ƒë·ªô ch√≠nh x√°c c·ªßa model Support Vector Machine(SVM)\nƒë·∫°t k·∫øt qu·∫£ v·ªõi ƒë·ªô ch√≠nh x√°c l√™n ƒë·∫øn h∆°n 98% v√† l√† k·∫øt qu·∫£ t·ªët nh·∫•t.\nTo√†n b·ªô code cho b√†i vi·∫øt nh∆∞ sau:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  # compare algorithms\r from pandas import read_csv\rfrom matplotlib import pyplot\rfrom sklearn.model_selection import train_test_split\rfrom sklearn.model_selection import cross_val_score\rfrom sklearn.model_selection import StratifiedKFold\rfrom sklearn.linear_model import LogisticRegression\rfrom sklearn.tree import DecisionTreeClassifier\rfrom sklearn.neighbors import KNeighborsClassifier\rfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\rfrom sklearn.naive_bayes import GaussianNB\rfrom sklearn.svm import SVC\r# Load dataset\r url = \u0026#34;https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\u0026#34;\rnames = [\u0026#39;sepal-length\u0026#39;, \u0026#39;sepal-width\u0026#39;, \u0026#39;petal-length\u0026#39;, \u0026#39;petal-width\u0026#39;, \u0026#39;class\u0026#39;]\rdataset = read_csv(url, names=names)\r# Split-out validation dataset\r array = dataset.values\rX = array[:,0:4]\ry = array[:,4]\rX_train, X_validation, Y_train, Y_validation = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\r# Spot Check Algorithms\r models = []\rmodels.append((\u0026#39;LR\u0026#39;, LogisticRegression(solver=\u0026#39;liblinear\u0026#39;, multi_class=\u0026#39;ovr\u0026#39;)))\rmodels.append((\u0026#39;LDA\u0026#39;, LinearDiscriminantAnalysis()))\rmodels.append((\u0026#39;KNN\u0026#39;, KNeighborsClassifier()))\rmodels.append((\u0026#39;CART\u0026#39;, DecisionTreeClassifier()))\rmodels.append((\u0026#39;NB\u0026#39;, GaussianNB()))\rmodels.append((\u0026#39;SVM\u0026#39;, SVC(gamma=\u0026#39;auto\u0026#39;)))\r# evaluate each model in turn\r results = []\rnames = []\rfor name, model in models:\rkfold = StratifiedKFold(n_splits=10, random_state=1)\rcv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=\u0026#39;accuracy\u0026#39;)\rresults.append(cv_results)\rnames.append(name)\rprint(\u0026#39;%s: %f(%f)\u0026#39; % (name, cv_results.mean(), cv_results.std()))\r# Compare Algorithms\r pyplot.boxplot(results, labels=names)\rpyplot.title(\u0026#39;Algorithm Comparison\u0026#39;)\rpyplot.show()\r  3.5.5. D·ª± ƒëo√°n k·∫øt qu·∫£ B√¢y gi·ªù ch√∫ng ta ch·ªçn m·ªôt model t·ªët nh·∫•t ƒë·ªÉ d·ª± ƒëo√°n. Th√¨ theo nh∆∞ k·∫øt qu·∫£ ·ªü tr√™n th√¨ ch√∫ng ta s·∫Ω ch·ªçn SVM l√† model cu·ªëi c√πng ƒë·ªÉ d·ª± ƒëo√°n.\nCh√∫ng ta s·∫Ω d·ª± ƒëo√°n d·ª±a tr√™n t·∫≠p validation set m√† ch√∫ng ta ƒë√£ t√°ch ·ªü m·ª•c 3.5.1.\nƒê√¢y l√† d·ªØ li·ªáu kh√¥ng h·ªÅ li√™n quan t·ªõi model trong qu√° tr√¨nh training. M·ª•c ƒë√≠ch c·ªßa vi·ªác d·ª± ƒëo√°n tr√™n t·∫≠p d·ªØ li·ªáu n√†y ƒë·ªÉ ƒë√°nh gi√° xem model ch√∫ng ta ch·ªçn c√≥ th·ª±c s·ª± d·ª± ƒëo√°n t·ªët hay kh√¥ng, ƒë·ªÉ t·ª´ ƒë√≥ bi·∫øt ƒë∆∞·ª£c n√≥ c√≥ b·ªã overfitting hay kh√¥ng.\nƒê·∫ßu ti√™n ch√∫ng ta fit model tr√™n to√†n b·ªô t·∫≠p train v√† d·ª± ƒëo√°n tr√™n to√†n b·ªô t·∫≠p validation.\n1 2 3 4 5 6  # Make predictions on validation dataset\r model = SVC(gamma=\u0026#39;auto\u0026#39;)\rmodel.fit(X_train, Y_train)\rpredictions = model.predict(X_validation)\r# Evaluate predictions\r print(accuracy_score(Y_validation, predictions))\r  K·∫øt qu·∫£ c·ªßa ch√∫ng ta l√†:\n 0.9666666666666667\n[[11 0 0]\n[ 0 12 1]\n[ 0 0 6]]\n Ho·∫∑c ch√∫ng ta c√≥ th·ªÉ l√™n google download ·∫£nh c·ªßa m·ªôt lo√†i hoa thu·ªôc m·ªôt trong 3 lo·∫°i hoa ·ªü tr√™n v√† cho v√†o model ƒë·ªÉ xem model d·ª± ƒëo√°n xem l√† lo√†i hoa g√¨ nh√©.\nCh√∫ng ta c√≥ th·ªÉ s·ª≠ d·ª•ng precision, recall\u0026hellip; ƒë·ªÉ show k·∫øt qu·∫£.\nprint(confusion_matrix(Y_validation, predictions))\rprint(classification_report(Y_validation, predictions))\rV√† k·∫øt qu·∫£:\n    precision recall f1-score support     Iris-setosa 1.00 1.00 1.00 11   Iris-versicolor 1.00 0.92 0.96 13   Iris-virginica 0.86 1.00 0.92 6       accuracy  0.97 30     macro avg 0.95 0.97 0.96 30   weighted avg 0.97 0.97 0.97 30    V·∫≠y l√† ch√∫ng ta ƒë√£ c∆° b·∫£n ho√†n th√†nh b√†i to√°n ƒë·∫ßu ti√™n c·ªßa Machine Learning.\n4. T·ªïng K·∫øt  B√†i vi·∫øt n√†y nh·∫±m m·ª•c ƒë√≠ch gi√∫p c√°c b·∫°n hi·ªÉu ƒë∆∞·ª£c lu·ªìng ho·∫°t ƒë·ªông hay n√≥i c√°ch kh√°c l√† c√°ch ƒë·ªÉ l√†m m·ªôt b√†i to√°n machine learning n√™n m√¨nh s·∫Ω kh√¥ng ƒëi chi ti·∫øt v√†o t·ª´ng d√≤ng code. M·∫∑c ƒë·ªãnh ban ƒë·∫ßu l√† c√°c b·∫°n ƒë√£ c√≥ ki·∫øn th·ª©c c∆° b·∫£n m√† b√†i vi·∫øt ƒë√£ y√™u c·∫ßu n√™n m√¨nh c≈©ng kh√¥ng n√≥i r√µ t·ª´ng th∆∞ vi·ªán, t·ª´ng kh√°i ni·ªám trong b√†i vi·∫øt n·ªØa. ƒê√¢y l√† b√†i vi·∫øt ƒë·∫ßu ti√™n trong lo·∫°t b√†i ML c∆° b·∫£n n√™n c√≥ r·∫•t nhi·ªÅu h·∫°n ch·∫ø v√† thi·∫øu s√≥t, r·∫•t mong ƒë∆∞·ª£c s·ª± g√≥p √Ω c·ªßa c√°c b·∫°n( m√¨nh s·∫Ω c·∫£i thi·ªán d·∫ßn trong nh·ªØng b√†i vi·∫øt sau). Nh∆∞ng hy v·ªçng qua b√†i vi·∫øt n√†y c√°c b·∫°n ƒë√£ bi·∫øt c√°ch x√¢y d·ª±ng m·ªôt b√†i to√°n machine learning.  C·∫£m ∆°n t·∫•t c·∫£ c√°c b·∫°n ƒë√£ ƒë·ªçc b√†i vi·∫øt. B√†i vi·∫øt ti·∫øp theo s·∫Ω l√† c√°ch x·ª≠ l√Ω d·ªØ li·ªáu, cleaning data nh∆∞ th·∫ø n√†o. Mong c√°c b·∫°n ƒë√≥n ƒë·ªçc!!!\n","description":"ƒê√¢y l√† b√†i to√°n ƒë·∫ßu ti√™n trong lo·∫°t b√†i ML c∆° b·∫£n","id":1,"section":"posts","tags":["tutorial","machine learning"],"title":"Gi·∫£i b√†i to√°n Machine Learning ƒë·∫ßu ti√™n ","uri":"https://tranvanly107.github.io/posts/first-machine-learning/"}]